{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Evaluate predictions\n",
    "This notebook serves as a general evaluation of the predictions made on the test dataset.\n",
    "\n",
    "The prediction file should have the following columns:\n",
    "- contributor\n",
    "- type (Human, Bot)\n",
    "\n",
    "We will compare the predictions made with the real labels and compute the following metrics:\n",
    "- recall\n",
    "- precision\n",
    "- weighted f1-score\n",
    "- accuracy\n",
    "- roc-auc\n",
    "- num_contributors\n",
    "- tn_fp_fn_tp"
   ],
   "id": "c91897599c801eec"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-06T11:28:33.396094Z",
     "start_time": "2025-01-06T11:28:33.393636Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, make_scorer, precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, auc"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Parameters\n",
    "The metrics will be added at the end the given evaluation file. The \"NAME\" variable is used to identify the evaluation in the file."
   ],
   "id": "e4d97dfbfb25047b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T11:28:33.416996Z",
     "start_time": "2025-01-06T11:28:33.413952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "RESOURCE_FOLDER = '../resources'\n",
    "DATA_FOLDER = f'{RESOURCE_FOLDER}/data'\n",
    "EVAL_FOLDER = f'{RESOURCE_FOLDER}/evals'\n",
    "\n",
    "LABELS_FILE = 'contributors.csv'\n",
    "PRED_FILE = 'ghmap_predictions.csv'\n",
    "EVAL_FILE = 'evaluation.csv'\n",
    "NAME = 'ghmap'"
   ],
   "id": "f3fca498eb917577",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1 - Load data",
   "id": "3a0d89ecab22c091"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.1 - Load predictions",
   "id": "5b6e1084af71e93"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T11:28:33.472986Z",
     "start_time": "2025-01-06T11:28:33.464307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_prediction = pd.read_csv(f\"{EVAL_FOLDER}/{PRED_FILE}\")\n",
    "df_prediction.drop(columns=['confidence'], inplace=True)\n",
    "df_prediction.head()"
   ],
   "id": "e31146ed6319c34",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      contributor   type\n",
       "0   otc-zuul[bot]    Bot\n",
       "1          ljharb  Human\n",
       "2  juancarlospaco  Human\n",
       "3        tldr-bot    Bot\n",
       "4       jakirkham  Human"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contributor</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>otc-zuul[bot]</td>\n",
       "      <td>Bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ljharb</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>juancarlospaco</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tldr-bot</td>\n",
       "      <td>Bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jakirkham</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Remove the unknown (< 5 events) and invalid (not found) contributors.",
   "id": "4066bf5d0ea10036"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T11:28:33.545986Z",
     "start_time": "2025-01-06T11:28:33.543004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Remove the 'Unknown' and Invalid types\n",
    "df_prediction = df_prediction[df_prediction['type'] != 'Unknown']\n",
    "df_prediction = df_prediction[df_prediction['type'] != 'Invalid']"
   ],
   "id": "dd4dc92638d7cc35",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Convert Bot and Human to 1 and 0 respectively.",
   "id": "aff3726e82bcf351"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T11:28:33.600650Z",
     "start_time": "2025-01-06T11:28:33.593330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "contributor_map = {\n",
    "    'Bot': 1,\n",
    "    'Human': 0\n",
    "}\n",
    "\n",
    "df_prediction['type'] = df_prediction['type'].map(contributor_map)\n",
    "\n",
    "# Set column type to int\n",
    "df_prediction['type'] = df_prediction['type'].astype(int)\n",
    "df_prediction.head()"
   ],
   "id": "690fc9979638ef3c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      contributor  type\n",
       "0   otc-zuul[bot]     1\n",
       "1          ljharb     0\n",
       "2  juancarlospaco     0\n",
       "3        tldr-bot     1\n",
       "4       jakirkham     0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contributor</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>otc-zuul[bot]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ljharb</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>juancarlospaco</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tldr-bot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jakirkham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.2 - Load labels",
   "id": "7d1cca638393cf08"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T11:28:33.708941Z",
     "start_time": "2025-01-06T11:28:33.698588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_labels = pd.read_csv(f\"{DATA_FOLDER}/{LABELS_FILE}\")\n",
    "# rename the column bot as true_type\n",
    "df_labels.rename(columns={'bot': 'true_type'}, inplace=True)\n",
    "\n",
    "# Merge the labels with the predictions\n",
    "df_compare = df_prediction.merge(df_labels, on='contributor')\n",
    "\n",
    "df_compare.head()"
   ],
   "id": "bd83e25a69eea52",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      contributor  type  true_type\n",
       "0   otc-zuul[bot]     1          1\n",
       "1          ljharb     0          0\n",
       "2  juancarlospaco     0          0\n",
       "3        tldr-bot     1          1\n",
       "4       jakirkham     0          0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contributor</th>\n",
       "      <th>type</th>\n",
       "      <th>true_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>otc-zuul[bot]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ljharb</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>juancarlospaco</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tldr-bot</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jakirkham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2 - Evaluate predictions",
   "id": "c34becab914583ae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.1 - Define the metrics",
   "id": "6c70e8cc92419d17"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T11:28:33.809236Z",
     "start_time": "2025-01-06T11:28:33.801637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Taken from RABBIT\n",
    "\n",
    "def botrecall(y_true, y_pred):\n",
    "    return precision_recall_fscore_support(y_true,y_pred,zero_division=0.0)[1][1]\n",
    "bot_recall = make_scorer(botrecall, greater_is_better=True)\n",
    "\n",
    "def humanrecall(y_true, y_pred):\n",
    "    return precision_recall_fscore_support(y_true,y_pred,zero_division=0.0)[1][0]\n",
    "human_recall = make_scorer(humanrecall, greater_is_better=True)\n",
    "\n",
    "def botprecision(y_true, y_pred):\n",
    "    return precision_recall_fscore_support(y_true,y_pred,zero_division=0.0)[0][1]\n",
    "bot_precision = make_scorer(botprecision, greater_is_better=True)\n",
    "\n",
    "def humanprecision(y_true, y_pred):\n",
    "    return precision_recall_fscore_support(y_true,y_pred,zero_division=0.0)[0][0]\n",
    "human_precision = make_scorer(humanprecision, greater_is_better=True)\n",
    "\n",
    "def wpscore(y_true, y_pred):\n",
    "    return precision_recall_fscore_support(y_true,y_pred,average='weighted',zero_division=0.0)[0]\n",
    "wprecision_score = make_scorer(wpscore, greater_is_better=True)\n",
    "\n",
    "def wrscore(y_true, y_pred):\n",
    "    return precision_recall_fscore_support(y_true,y_pred,average='weighted',zero_division=0.0)[1]\n",
    "wrecall_score = make_scorer(wrscore, greater_is_better=True)\n",
    "\n",
    "def auc_pr(y_true, y_pred):\n",
    "    P, R, T = precision_recall_curve(y_true, y_pred)\n",
    "    return auc(R, P)\n",
    "\n",
    "auc_pr = make_scorer(auc_pr, greater_is_better=True)"
   ],
   "id": "74e3775e9107032b",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.2 - Evaluate predictions",
   "id": "27875b7337d92fc7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T11:28:33.880881Z",
     "start_time": "2025-01-06T11:28:33.857162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_pred = df_compare['type']\n",
    "y_test = df_compare['true_type']\n",
    "\n",
    "perf = {\n",
    "    'precision': [precision_score(y_test, y_pred, average='weighted', zero_division=0.0)],\n",
    "    'bot_precision': [botprecision(y_test, y_pred)],\n",
    "    'human_precision': [humanprecision(y_test, y_pred)],\n",
    "    'recall': [recall_score(y_test, y_pred, average='weighted', zero_division=0.0)],\n",
    "    'bot_recall': [botrecall(y_test, y_pred)],\n",
    "    'human_recall': [humanrecall(y_test, y_pred)],\n",
    "    'weighted_f1': [f1_score(y_test, y_pred, average='weighted', zero_division=0.0)],\n",
    "    'accuracy': [accuracy_score(y_test, y_pred)],\n",
    "    'tn_fp_fn_tp': [confusion_matrix(y_test, y_pred).ravel()],\n",
    "    'num_contrib': df_prediction.index.nunique(),\n",
    "    'roc_auc': [roc_auc_score(y_test, y_pred)]\n",
    "}\n",
    "\n",
    "performance = pd.DataFrame.from_dict(perf)\n",
    "performance.index = [NAME]"
   ],
   "id": "a7b6e3df427ec025",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T11:28:33.943253Z",
     "start_time": "2025-01-06T11:28:33.932407Z"
    }
   },
   "cell_type": "code",
   "source": "display(performance)",
   "id": "47eccb98abd948b5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       precision  bot_precision  human_precision    recall  bot_recall  \\\n",
       "ghmap   0.894093       0.897638         0.890585  0.894057    0.888312   \n",
       "\n",
       "       human_recall  weighted_f1  accuracy         tn_fp_fn_tp  num_contrib  \\\n",
       "ghmap      0.899743     0.894051  0.894057  [350, 39, 43, 342]          774   \n",
       "\n",
       "        roc_auc  \n",
       "ghmap  0.894027  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>bot_precision</th>\n",
       "      <th>human_precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>bot_recall</th>\n",
       "      <th>human_recall</th>\n",
       "      <th>weighted_f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>tn_fp_fn_tp</th>\n",
       "      <th>num_contrib</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ghmap</th>\n",
       "      <td>0.894093</td>\n",
       "      <td>0.897638</td>\n",
       "      <td>0.890585</td>\n",
       "      <td>0.894057</td>\n",
       "      <td>0.888312</td>\n",
       "      <td>0.899743</td>\n",
       "      <td>0.894051</td>\n",
       "      <td>0.894057</td>\n",
       "      <td>[350, 39, 43, 342]</td>\n",
       "      <td>774</td>\n",
       "      <td>0.894027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.3 - Save the evaluation",
   "id": "36a5065763d84da3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T11:28:34.014554Z",
     "start_time": "2025-01-06T11:28:34.009446Z"
    }
   },
   "cell_type": "code",
   "source": "df_eval = pd.read_csv(f\"{EVAL_FOLDER}/{EVAL_FILE}\", index_col=0)",
   "id": "ad5b0ae7f7ef55bd",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T11:28:34.142164Z",
     "start_time": "2025-01-06T11:28:34.134157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# If the evaluation already exists, replace the line\n",
    "if NAME in df_eval.index:\n",
    "    df_eval.drop(index=NAME, inplace=True)\n",
    "df_eval = pd.concat([df_eval, performance], axis=0)\n",
    "df_eval.to_csv(f\"{EVAL_FOLDER}/{EVAL_FILE}\", index=True)\n"
   ],
   "id": "3db05902b25e2d9c",
   "outputs": [],
   "execution_count": 33
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
