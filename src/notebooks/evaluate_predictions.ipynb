{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Evaluate predictions\n",
    "This notebook serves as a general evaluation of the predictions made on the test dataset.\n",
    "The results will be added to the evaluation file with the given NAME as index.\n",
    "\n",
    "Constants to change:\n",
    "- PRED_FILE : the name of the csv containing the predictions\n",
    "- EVAL_FILE : the name of the csv to save the evaluation\n",
    "- NAME : the name of the evaluation (used as index in the evaluation file)\n",
    "\n",
    "\n",
    "The prediction file should have the following columns:\n",
    "- contributor\n",
    "- true_bot (Human, Bot)\n",
    "- predicted_bot (Human, Bot)\n",
    "\n",
    "We will compare the predictions made with the real labels and compute the following metrics:\n",
    "- recall\n",
    "- precision\n",
    "- weighted f1-score\n",
    "- accuracy\n",
    "- roc-auc\n",
    "- num_contributors\n",
    "- tn_fp_fn_tp\n"
   ],
   "id": "c91897599c801eec"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-14T15:56:17.370865Z",
     "start_time": "2025-01-14T15:56:17.318999Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, make_scorer, precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, auc"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Parameters\n",
    "The metrics will be added at the end the given evaluation file. The \"NAME\" variable is used to identify the evaluation in the file."
   ],
   "id": "e4d97dfbfb25047b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T15:56:18.320360Z",
     "start_time": "2025-01-14T15:56:18.317452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "RESOURCE_FOLDER = '../resources'\n",
    "DATA_FOLDER = f'{RESOURCE_FOLDER}/data'\n",
    "EVAL_FOLDER = f'{RESOURCE_FOLDER}/evals'\n",
    "\n",
    "PRED_FILE = 'ghmap_predictions.csv'\n",
    "EVAL_FILE = 'evaluation.csv'\n",
    "NAME = 'ghmap'"
   ],
   "id": "f3fca498eb917577",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1 - Load data",
   "id": "3a0d89ecab22c091"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.1 - Load predictions",
   "id": "5b6e1084af71e93"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T15:56:21.400399Z",
     "start_time": "2025-01-14T15:56:21.389810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_prediction = pd.read_csv(f\"{EVAL_FOLDER}/{PRED_FILE}\", index_col=0)\n",
    "df_prediction.drop(columns=['confidence'], inplace=True)\n",
    "display(df_prediction.head())\n",
    "\n"
   ],
   "id": "e31146ed6319c34",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               true_bot predicted_bot\n",
       "contributor                          \n",
       "otc-zuul[bot]       Bot           Bot\n",
       "ljharb            Human         Human\n",
       "juancarlospaco    Human         Human\n",
       "tldr-bot            Bot           Bot\n",
       "jakirkham         Human         Human"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_bot</th>\n",
       "      <th>predicted_bot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contributor</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>otc-zuul[bot]</th>\n",
       "      <td>Bot</td>\n",
       "      <td>Bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ljharb</th>\n",
       "      <td>Human</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>juancarlospaco</th>\n",
       "      <td>Human</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tldr-bot</th>\n",
       "      <td>Bot</td>\n",
       "      <td>Bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jakirkham</th>\n",
       "      <td>Human</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Remove the unknown (< 5 events) and invalid (not found) contributors.",
   "id": "4066bf5d0ea10036"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T15:56:23.048427Z",
     "start_time": "2025-01-14T15:56:23.044832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Remove the 'Unknown' and Invalid types\n",
    "df_prediction = df_prediction[df_prediction['predicted_bot'] != 'Unknown']\n",
    "df_prediction = df_prediction[df_prediction['predicted_bot'] != 'Invalid']"
   ],
   "id": "dd4dc92638d7cc35",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Convert Bot and Human to 1 and 0 respectively.",
   "id": "aff3726e82bcf351"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T15:56:24.681543Z",
     "start_time": "2025-01-14T15:56:24.673766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "contributor_map = {\n",
    "    'Bot': 1,\n",
    "    'Human': 0\n",
    "}\n",
    "\n",
    "df_prediction['predicted_bot'] = df_prediction['predicted_bot'].map(contributor_map)\n",
    "\n",
    "# Set column type to int\n",
    "df_prediction['predicted_bot'] = df_prediction['predicted_bot'].astype(int)\n",
    "df_prediction.head()"
   ],
   "id": "690fc9979638ef3c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               true_bot  predicted_bot\n",
       "contributor                           \n",
       "otc-zuul[bot]       Bot              1\n",
       "ljharb            Human              0\n",
       "juancarlospaco    Human              0\n",
       "tldr-bot            Bot              1\n",
       "jakirkham         Human              0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_bot</th>\n",
       "      <th>predicted_bot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contributor</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>otc-zuul[bot]</th>\n",
       "      <td>Bot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ljharb</th>\n",
       "      <td>Human</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>juancarlospaco</th>\n",
       "      <td>Human</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tldr-bot</th>\n",
       "      <td>Bot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jakirkham</th>\n",
       "      <td>Human</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.2 - Load labels",
   "id": "7d1cca638393cf08"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T15:56:26.588897Z",
     "start_time": "2025-01-14T15:56:26.582504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_prediction['true_bot'] = df_prediction['true_bot'].map(contributor_map)\n",
    "df_prediction['true_bot'] = df_prediction['true_bot'].astype(int)\n",
    "df_prediction.head()"
   ],
   "id": "bd83e25a69eea52",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                true_bot  predicted_bot\n",
       "contributor                            \n",
       "otc-zuul[bot]          1              1\n",
       "ljharb                 0              0\n",
       "juancarlospaco         0              0\n",
       "tldr-bot               1              1\n",
       "jakirkham              0              0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_bot</th>\n",
       "      <th>predicted_bot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contributor</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>otc-zuul[bot]</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ljharb</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>juancarlospaco</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tldr-bot</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jakirkham</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2 - Evaluate predictions",
   "id": "c34becab914583ae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.1 - Define the metrics",
   "id": "6c70e8cc92419d17"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T15:56:28.312614Z",
     "start_time": "2025-01-14T15:56:28.307207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Taken from RABBIT\n",
    "\n",
    "def botrecall(y_true, y_pred):\n",
    "    return precision_recall_fscore_support(y_true,y_pred,zero_division=0.0)[1][1]\n",
    "bot_recall = make_scorer(botrecall, greater_is_better=True)\n",
    "\n",
    "def humanrecall(y_true, y_pred):\n",
    "    return precision_recall_fscore_support(y_true,y_pred,zero_division=0.0)[1][0]\n",
    "human_recall = make_scorer(humanrecall, greater_is_better=True)\n",
    "\n",
    "def botprecision(y_true, y_pred):\n",
    "    return precision_recall_fscore_support(y_true,y_pred,zero_division=0.0)[0][1]\n",
    "bot_precision = make_scorer(botprecision, greater_is_better=True)\n",
    "\n",
    "def humanprecision(y_true, y_pred):\n",
    "    return precision_recall_fscore_support(y_true,y_pred,zero_division=0.0)[0][0]\n",
    "human_precision = make_scorer(humanprecision, greater_is_better=True)\n",
    "\n",
    "def wpscore(y_true, y_pred):\n",
    "    return precision_recall_fscore_support(y_true,y_pred,average='weighted',zero_division=0.0)[0]\n",
    "wprecision_score = make_scorer(wpscore, greater_is_better=True)\n",
    "\n",
    "def wrscore(y_true, y_pred):\n",
    "    return precision_recall_fscore_support(y_true,y_pred,average='weighted',zero_division=0.0)[1]\n",
    "wrecall_score = make_scorer(wrscore, greater_is_better=True)\n",
    "\n",
    "def auc_pr(y_true, y_pred):\n",
    "    P, R, T = precision_recall_curve(y_true, y_pred)\n",
    "    return auc(R, P)\n",
    "\n",
    "auc_pr = make_scorer(auc_pr, greater_is_better=True)"
   ],
   "id": "74e3775e9107032b",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.2 - Evaluate predictions",
   "id": "27875b7337d92fc7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T15:56:30.180733Z",
     "start_time": "2025-01-14T15:56:30.161475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_pred = df_prediction['predicted_bot']\n",
    "y_test = df_prediction['true_bot']\n",
    "\n",
    "perf = {\n",
    "    'precision': [precision_score(y_test, y_pred, average='weighted', zero_division=0.0)],\n",
    "    'bot_precision': [botprecision(y_test, y_pred)],\n",
    "    'human_precision': [humanprecision(y_test, y_pred)],\n",
    "    'recall': [recall_score(y_test, y_pred, average='weighted', zero_division=0.0)],\n",
    "    'bot_recall': [botrecall(y_test, y_pred)],\n",
    "    'human_recall': [humanrecall(y_test, y_pred)],\n",
    "    'weighted_f1': [f1_score(y_test, y_pred, average='weighted', zero_division=0.0)],\n",
    "    'accuracy': [accuracy_score(y_test, y_pred)],\n",
    "    'tn_fp_fn_tp': [confusion_matrix(y_test, y_pred).ravel()],\n",
    "    'num_contrib': df_prediction.index.nunique(),\n",
    "    'roc_auc': [roc_auc_score(y_test, y_pred)]\n",
    "}\n",
    "\n",
    "performance = pd.DataFrame.from_dict(perf)\n",
    "performance.index = [NAME]"
   ],
   "id": "a7b6e3df427ec025",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T15:56:31.731275Z",
     "start_time": "2025-01-14T15:56:31.723426Z"
    }
   },
   "cell_type": "code",
   "source": "display(performance)",
   "id": "47eccb98abd948b5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       precision  bot_precision  human_precision    recall  bot_recall  \\\n",
       "ghmap   0.895178       0.897849         0.892583  0.895151    0.888298   \n",
       "\n",
       "       human_recall  weighted_f1  accuracy         tn_fp_fn_tp  num_contrib  \\\n",
       "ghmap      0.901809      0.89514  0.895151  [349, 38, 42, 334]          763   \n",
       "\n",
       "        roc_auc  \n",
       "ghmap  0.895053  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>bot_precision</th>\n",
       "      <th>human_precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>bot_recall</th>\n",
       "      <th>human_recall</th>\n",
       "      <th>weighted_f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>tn_fp_fn_tp</th>\n",
       "      <th>num_contrib</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ghmap</th>\n",
       "      <td>0.895178</td>\n",
       "      <td>0.897849</td>\n",
       "      <td>0.892583</td>\n",
       "      <td>0.895151</td>\n",
       "      <td>0.888298</td>\n",
       "      <td>0.901809</td>\n",
       "      <td>0.89514</td>\n",
       "      <td>0.895151</td>\n",
       "      <td>[349, 38, 42, 334]</td>\n",
       "      <td>763</td>\n",
       "      <td>0.895053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.3 - Save the evaluation",
   "id": "36a5065763d84da3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T15:56:49.479065Z",
     "start_time": "2025-01-14T15:56:49.474344Z"
    }
   },
   "cell_type": "code",
   "source": "df_eval = pd.read_csv(f\"{EVAL_FOLDER}/{EVAL_FILE}\", index_col=0)",
   "id": "ad5b0ae7f7ef55bd",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T15:56:50.471144Z",
     "start_time": "2025-01-14T15:56:50.465765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# If the evaluation already exists, replace the line\n",
    "if NAME in df_eval.index:\n",
    "    df_eval.drop(index=NAME, inplace=True)\n",
    "df_eval = pd.concat([df_eval, performance], axis=0)\n",
    "df_eval.index.name = 'model'\n",
    "df_eval.to_csv(f\"{EVAL_FOLDER}/{EVAL_FILE}\", index=True)\n"
   ],
   "id": "3db05902b25e2d9c",
   "outputs": [],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
